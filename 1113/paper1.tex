
\documentclass{article}

\title{"CrawlPhish: Large-scale Analysis of Client-side Cloaking Techniques in Phishing" Summary}
\author{Robert Krzysztof Robert Noparlik}


\begin{document}
\maketitle

\section{Summary}

This paper is concerned with analyzing cloaking techniques used by phishing websites to evade detection by automated security systems. To do this, the authors developed a system, dubbed "CrawlPhish" to check and analyze these websites. They found that client-side cloaking techniques fall into three main categories:

\begin{itemize}
	\item User-interaction - a phishing website requires a user to click through a popup or move a mouse in order to trigger rendering of the website.
	\item Bot Behavior - signs of a bot accessing the website: checks if a website is requested immediately after failing to load, or include random duration timers before being able to use the website which might throw the naive crawlers off the trail.
	\item Fingerprinting - uses things like cookies, referrer headers and user agents to determine if the client is an actual user or one of a crawler.
\end{itemize}

The study found most client-side cloaking techniques appeared in 2018 and the number of websites that leveraged these cloaking abilities grew by around 3\%, from 20.79\% in 2018 to 24.04\% in 2019. The cloaking group that saw the most growth was the \textit{User Interaction} group, which saw a growth of 20\% (from 40.11\% in 2018 to 61.23\%) in 2019. In spite of use of most types of cloaking techniques being on an upwards trend, use of cloaking classified as relating to \textit{Bot Behavior} has seen a dramatic decrease of their use. In general, use of cloaking techniques is getting more and more common.


\section{Pros}

\begin{itemize}
	\item First in-depth analysis of client-side cloaking techniques.
	\item Interesting way to analyze website content - taking screenshots of the website generated by every (forced) JS execution path.
\end{itemize}

\section{Cons}

\begin{itemize}
	\item Data seems to be only from 2018 and 2019.
	\item This paper, in my opinion, is a bit all over the place and feels like it's being stretched to achieve the desired number of pages.
\end{itemize}

\section{Meaning}

This paper is the first of its kind to analyze client-side cloaking techniques. The authors, by the use of CrawlPhish, are able to detect if a website uses cloaking techniques and what kind of techniques are employed by the phishing website. In addition, due to the data they have gathered, they were able to track how commonplace were certain approaches to cloaking and also track the origin of each implementation for every website, as attackers generally reuse and only slightly modify their code.

Since 2018 client-side cloaking techniques were becoming increasingly more common, while academia was focusing server-side cloaking techniques. This paper seems to be the first to analyze them in depth, hopefully overturning the trend.


\section{Discussion}

\begin{itemize}
	\item How does "randomization" help a suspected bot? 
\end{itemize}



\end{document}